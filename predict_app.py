# -*- coding: utf-8 -*-
# ÙˆØ§Ø¬Ù‡Ø© Streamlit Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ù‘Ø¨Ø© ÙˆØ¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø§Ø´Ø©
# ÙˆØ¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ Excel Ù…Ø¹ Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø© Ù„ÙƒÙ„ Ø­Ø§Ù„Ø©

from pathlib import Path
import io
import time
import numpy as np
import pandas as pd
import joblib
import streamlit as st
from sklearn.metrics import (
    roc_auc_score, average_precision_score, accuracy_score,
    precision_score, recall_score, f1_score, confusion_matrix
)

# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙƒÙ…Ø§ Ø²ÙˆÙ‘Ø¯ØªÙ†ÙŠ
# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ (Ù†Ø³Ø¨ÙŠÙ‘Ø© Ù„Ù„Ù…Ø³ØªÙˆØ¯Ø¹/Ø§Ù„ØªØ·Ø¨ÙŠÙ‚)
REPO_DIR   = Path(__file__).resolve().parent
MODELS_DIR = REPO_DIR / "models"
RESULTS_DIR = REPO_DIR / "results"
RESULTS_DIR.mkdir(parents=True, exist_ok=True)


# ========== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© ==========
def load_excel_biggest_sheet(path_or_buf):
    """Ù‚Ø±Ø§Ø¡Ø© Ø£ÙƒØ¨Ø± ÙˆØ±Ù‚Ø© Ù…Ù† Ù…Ù„Ù Excel (ÙŠØ¯Ø¹Ù… Ø±ÙØ¹ Ù…Ù„Ù Ø¹Ø¨Ø± Streamlit Ø£Ùˆ Ù…Ø³Ø§Ø±)."""
    xl = pd.ExcelFile(path_or_buf)
    best_name, best_rows = None, -1
    for name in xl.sheet_names:
        df_tmp = xl.parse(name)
        if df_tmp.shape[0] > best_rows:
            best_name, best_rows = name, df_tmp.shape[0]
    df = xl.parse(best_name)
    df.columns = [str(c).strip() for c in df.columns]
    return df

def to_binary_y(series: pd.Series) -> np.ndarray:
    """ØªØ­ÙˆÙŠÙ„ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‡Ø¯Ù Ø¥Ù„Ù‰ 0/1 Ø¹Ù†Ø¯ ØªÙˆÙÙ‘Ø±Ù‡ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)."""
    if series.dtype.kind in "if":
        return (series.astype(float) > 0).astype(int).values
    mapper = {"1":1,"0":0,"true":1,"false":0,"yes":1,"no":0,"Ù†Ø¹Ù…":1,"Ù„Ø§":0}
    y = series.astype(str).str.lower().str.strip().map(mapper)
    if y.isna().any():
        y = pd.Categorical(series).codes
        if len(np.unique(y)) != 2:
            raise ValueError("Target ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù„ÙŠØ³ Ø«Ù†Ø§Ø¦ÙŠÙ‹Ø§.")
    return y.values

def coerce_numeric_df(df: pd.DataFrame) -> pd.DataFrame:
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¥Ù† Ø£Ù…ÙƒÙ† (ØºÙŠØ± Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© ØªØ¨Ù‚Ù‰ NaN)."""
    out = df.copy()
    for c in out.columns:
        if out[c].dtype == object:
            out[c] = pd.to_numeric(out[c], errors="coerce")
    return out

def predict_with_bundle(bundle_path: Path, test_df: pd.DataFrame, threshold: float = 0.5):
    """ØªØ´ØºÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­ÙÙˆØ¸ (bundle ÙŠØ­ØªÙˆÙŠ imputer/scaler/model/columns/target_col) Ø¹Ù„Ù‰ DataFrame."""
    bundle = joblib.load(bundle_path)
    model    = bundle["model"]
    imputer  = bundle["imputer"]
    scaler   = bundle["scaler"]
    columns  = bundle["columns"]
    target_col = bundle.get("target_col", "Target")

    # Ù‡Ø¯Ù Ø­Ù‚ÙŠÙ‚ÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ù„Ù…Ù‚Ø§ÙŠÙŠØ³)
    y_true = None
    if target_col in test_df.columns:
        try:
            y_true = to_binary_y(test_df[target_col])
        except Exception:
            y_true = None

    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ù†ÙØ³ ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    X_df = test_df.drop(columns=[target_col], errors="ignore")
    for c in columns:
        if c not in X_df.columns:
            X_df[c] = np.nan  # Ø£Ø¹Ù…Ø¯Ø© Ù†Ø§Ù‚ØµØ©
    X_df = X_df[columns]     # ØªØ¬Ø§Ù‡Ù„ Ø£ÙŠ Ø£Ø¹Ù…Ø¯Ø© Ø²Ø§Ø¦Ø¯Ø©
    X_df = coerce_numeric_df(X_df)

    # Ù†ÙØ³ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª
    X = imputer.transform(X_df.values)
    if scaler is not None:
        X = scaler.transform(X)

    # Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª ØªÙ†Ø¨Ø¤ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©
    if hasattr(model, "predict_proba"):
        prob = model.predict_proba(X)[:, 1]
    else:
        s = model.decision_function(X)
        prob = (s - s.min())/(s.max()-s.min()+1e-9)

    # Ù…Ù„ØµÙ‚ Ù…ØªÙ†Ø¨Ø£ + Ù†Ø³Ø¨Ø© Ø«Ù‚Ø© Ø§Ù„ØªÙ†Ø¨Ø¤
    pred = (prob >= float(threshold)).astype(int)
    # "Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©" = Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§
    confidence = np.where(pred == 1, prob, 1.0 - prob)
    confidence_pct = (confidence * 100.0).round(2)

    return prob, pred, confidence, confidence_pct, y_true, target_col

def build_summary_df(test_df: pd.DataFrame, y_true, pred, prob, threshold: float):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ø¹Ø±Ø¶/Ø§Ù„ØªØµØ¯ÙŠØ±."""
    n = len(test_df)
    detected = int((pred == 1).sum())
    not_detected = int((pred == 0).sum())

    rows = [
        ["Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª", n],
        ["Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© (threshold)", threshold],
        ["Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© (pred=1)", detected],
        ["Ù†Ø³Ø¨Ø© Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ù…Ù† Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ", round(detected / n, 4) if n else 0.0],
        ["Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø§Ù„Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙƒØªØ´ÙØ© (pred=0)", not_detected],
        ["Ù†Ø³Ø¨Ø© Ø§Ù„Ø­Ø§Ù„Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ù…Ù† Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ", round(not_detected / n, 4) if n else 0.0],
    ]

    if y_true is not None:
        try:
            tn, fp, fn, tp = confusion_matrix(y_true, pred, labels=[0,1]).ravel()
            acc  = accuracy_score(y_true, pred)
            prec = precision_score(y_true, pred, zero_division=0)
            rec  = recall_score(y_true, pred, zero_division=0)
            f1   = f1_score(y_true, pred, zero_division=0)
            try:
                roc_auc = roc_auc_score(y_true, prob)
            except Exception:
                roc_auc = np.nan
            try:
                pr_auc = average_precision_score(y_true, prob)
            except Exception:
                pr_auc = np.nan
            # Ù…Ù‚Ø§ÙŠÙŠØ³ Ù„Ù„ÙØ¦Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø©:
            npv  = tn / (tn + fn) if (tn + fn) > 0 else 0.0
            spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0

            rows += [
                ["Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙƒÙ„ÙŠØ© (Accuracy)", round(acc, 4)],
                ["ROC-AUC", round(float(roc_auc), 4) if roc_auc == roc_auc else ""],
                ["PR-AUC", round(float(pr_auc), 4) if pr_auc == pr_auc else ""],
                ["Ø¯Ù‚Ø© Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© (Precision1)", round(prec, 4)],
                ["Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© (Recall1)", round(rec, 4)],
                ["F1 Ù„Ù„ÙØ¦Ø© Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©", round(f1, 4)],
                ["Ø¯Ù‚Ø© Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø© (NPV)", round(npv, 4)],
                ["Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø© (Specificity)", round(spec, 4)],
                ["TP (ØµØ­ÙŠØ­ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ)", tp],
                ["FP (Ø®Ø§Ø·Ø¦ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ)", fp],
                ["TN (ØµØ­ÙŠØ­ Ø³Ù„Ø¨ÙŠ)", tn],
                ["FN (Ø®Ø§Ø·Ø¦ Ø³Ù„Ø¨ÙŠ)", fn],
            ]
        except Exception:
            pass

    return pd.DataFrame(rows, columns=["Ø§Ù„Ù…Ø¤Ø´Ø±", "Ø§Ù„Ù‚ÙŠÙ…Ø©"])

def make_excel_bytes(pred_df: pd.DataFrame, summary_df: pd.DataFrame) -> bytes:
    """ØªØ¬Ù‡ÙŠØ² Ù…Ù„Ù Excel Ø¨ØµÙØ­ØªÙŠÙ†: Predictions + Summary ÙˆØ¥Ø±Ø¬Ø§Ø¹Ù‡ ÙƒÙ€ bytes Ù„Ù„ØªÙ†Ø²ÙŠÙ„."""
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        pred_df.to_excel(writer, index=False, sheet_name="Predictions")
        summary_df.to_excel(writer, index=False, sheet_name="Summary")
    buf.seek(0)
    return buf.read()

# ========== ÙˆØ§Ø¬Ù‡Ø© Streamlit ==========
st.set_page_config(page_title="ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ù‘Ø¨Ø© (Excel)", layout="wide")
st.title("ØªØ´ØºÙŠÙ„/Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ù‘Ø¨Ø© ÙˆØ¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ Excel")

# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸
model_files = sorted(MODELS_DIR.glob("*.joblib"))
if not model_files:
    st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø­ÙÙˆØ¸Ø© Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ models/. Ù‚Ù… Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£ÙˆÙ„Ù‹Ø§ Ø¹Ø¨Ø± app.py.")
    st.stop()

default_idx = 0
for i, p in enumerate(model_files):
    if p.name.lower().startswith("lightgbm"):  # Ø§Ø®ØªÙŠØ§Ø± LightGBM ÙƒØ§ÙØªØ±Ø§Ø¶ÙŠ Ø¥Ù† ÙˆØ¬Ø¯
        default_idx = i

model_path = st.selectbox(
    "Ø§Ø®ØªØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:",
    model_files,
    index=default_idx,
    format_func=lambda p: p.name
)

# Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
upl = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ´ØºÙŠÙ„Ù‡ (xlsx):", type=["xlsx"])

# Ø§Ù„Ø¹ØªØ¨Ø©
thr = st.slider("Ø¹ØªØ¨Ø© Ø§Ù„Ù‚Ø±Ø§Ø± (threshold)", 0.0, 1.0, 0.50, 0.01)

# Ø²Ø± Ø§Ù„ØªØ´ØºÙŠÙ„
if st.button("ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ¥Ù†ØªØ§Ø¬ Ù…Ù„Ù Excel"):
    if upl is None:
        st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ Ù…Ù„Ù Excel Ø£ÙˆÙ„Ù‹Ø§.")
        st.stop()

    with st.spinner("Ø¬Ø§Ø±Ù Ø§Ù„ØªØ´ØºÙŠÙ„..."):
        try:
            test_df = load_excel_biggest_sheet(upl)

            prob, pred, conf, conf_pct, y_true, target_col = predict_with_bundle(
                model_path, test_df, threshold=thr
            )

            # Ø¨Ù†Ø§Ø¡ DataFrame Ø§Ù„Ù†ØªØ§Ø¦Ø¬ + Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©
            out_df = test_df.copy()
            out_df["prob_1"] = prob
            out_df["pred_label"] = pred
            out_df["confidence"] = conf                    # 0..1
            out_df["confidence_pct"] = conf_pct            # 0..100 %

            # Ù…Ù„Ø®Øµ Ù„Ù„Ø¹Ø±Ø¶ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø§Ø´Ø© + Ø§Ù„ØªØµØ¯ÙŠØ±
            summary_df = build_summary_df(test_df, y_true, pred, prob, threshold=thr)

            # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„Ø®Øµ ÙÙŠ Ø´Ø§Ø´Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
            st.subheader("ğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ")
            st.dataframe(summary_df, use_container_width=True)

            # Ø­ÙØ¸ Ù…Ù„Ù Excel Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Øµ + Ø²Ø± ØªÙ†Ø²ÙŠÙ„
            ts = time.strftime("%Y%m%d-%H%M%S")
            out_name = f"pred_{model_path.stem}_thr{thr:.2f}_{ts}.xlsx"
            out_path = RESULTS_DIR / out_name

            # Ø¨ÙÙ†Ù’ÙŠÙØ© Excel Ø¨ØµÙØ­ØªÙŠÙ†
            excel_bytes = make_excel_bytes(out_df, summary_df)
            with open(out_path, "wb") as f:
                f.write(excel_bytes)

            st.success(f"ØªÙ… Ø§Ù„ØªØ´ØºÙŠÙ„ ÙˆØ­ÙØ¸ Ù…Ù„Ù Excel ÙÙŠ: {out_path}")

            # ØªÙ…ÙƒÙŠÙ† Ø§Ù„ØªÙ†Ø²ÙŠÙ„ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
            st.download_button(
                label="â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙƒÙ…Ù„Ù Excel",
                data=excel_bytes,
                file_name=out_name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

            # Ø¹Ø±Ø¶ Ø¹ÙŠÙ‘Ù†Ø© Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.subheader("ğŸ” Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            st.dataframe(out_df.head(30), use_container_width=True)

        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„: {e}")


    st.markdown("---")
st.markdown("ğŸ‘¨â€ğŸ’» **ØªØ·ÙˆÙŠØ± :** Ù…Ø´Ù‡ÙˆØ± Ø§Ù„Ø¹Ø¨Ø§Ø³ | 00966553339838 | ")
